{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea24999-6a2a-4c62-95da-90f32c398e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6e354-186c-42e1-a473-b12231523bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path, dataset):\n",
    "    return sorted(glob(f\"{path}/{dataset}/**.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba8772-5d3f-4b39-bb2c-6c5ba9e32717",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8232460-3b5c-47d4-9a62-ed9c9fadce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"aps-a\",  \n",
    "    \"aps-av\", \n",
    "    \"aps-cv\", \n",
    "    \"dblp\", \n",
    "    \"dblp-v\", \n",
    "    \"mus\", \n",
    "    \"ndc-ai\", \n",
    "    \"ndc-pc\", \n",
    "    \"sha\", \n",
    "    \"stex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acda766-f90a-491a-aef9-2ab0aecf9d80",
   "metadata": {},
   "source": [
    "### aps-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea7a22-3826-403e-bb89-99622324d7ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = \"aps-a\"\n",
    "nodes = \"authors\"\n",
    "dataset_type = \"ihg\"\n",
    "files = get_files(path, dataset)\n",
    "file = files[0]\n",
    "with gzip.open(file) as f:\n",
    "    df = pd.read_csv(file)\n",
    "df = df[[nodes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90116a3-d496-4700-a31a-0e2e0c4adb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "n_cells_filled = len(df_filtered[nodes].explode())\n",
    "n_edges = len(df_filtered)\n",
    "\n",
    "node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "n_nodes = len(node_mapping)\n",
    "\n",
    "print(\n",
    "    f\"n: {n_nodes}, m:{n_edges}\", \n",
    "    f\"c: {n_cells_filled}, c/nm: {n_cells_filled / (n_nodes * n_edges)}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e9dfc-8982-4fbb-a672-a3e679d44e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[nodes] = df_filtered[nodes].map(lambda x:\"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "df_filtered[nodes].to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e8d61-e6b9-4ba5-887d-83f86856977b",
   "metadata": {},
   "source": [
    "### aps-av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16b39f-f94c-4c3a-8c83-63c7f8241499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"aps-av\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"authors\"\n",
    "files = get_files(path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbd2ae-cfc3-4384-95bc-f75c1099e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df = df[[nodes]]\n",
    "    df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216301f-1eff-424d-9e26-dff79fd964b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3bb20-9e63-47db-8a5c-03b284d1e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \n",
    "                                         header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e314651-877f-4e75-b00d-3acbfc3da911",
   "metadata": {},
   "source": [
    "### aps-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4fa56-0d0a-400b-a79e-a3882b59c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"aps-cv\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"cited_doi\"\n",
    "files = get_files(path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd8125-8f36-4838-bfbf-ce34bef7d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df = df[[nodes]]\n",
    "    df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "    df_filtered = df_filtered[~(df_filtered[nodes].map(len) < 1)].copy()\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc10250-c4c5-458f-bdd8-0eaddbecd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faed488-a1ac-4d7d-ab97-08df2c1a9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \n",
    "                                         header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a589aaa0-184d-45d5-8350-2865b3b477a7",
   "metadata": {},
   "source": [
    "### dblp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bc9c0-4c5d-48d3-8677-57256af0651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dblp\"\n",
    "dataset_type = \"ihg\"\n",
    "nodes = \"author\"\n",
    "files = get_files(path, dataset)\n",
    "file = files[0]\n",
    "with gzip.open(file) as f:\n",
    "    df = pd.read_csv(file)\n",
    "df = df[[nodes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfc145-9b13-445a-925c-48194ae5247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "df_filtered[nodes] = df_filtered[nodes].map(lambda x:x.split(\";\"))\n",
    "df_filtered = df_filtered[~(df_filtered[nodes].map(len) < 1)].copy()\n",
    "n_cells_filled = len(df_filtered[nodes].explode())\n",
    "n_edges = len(df_filtered)\n",
    "\n",
    "node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "n_nodes = len(node_mapping)\n",
    "\n",
    "print(\n",
    "    f\"n: {n_nodes}, m:{n_edges}\", \n",
    "    f\"c: {n_cells_filled}, c/nm: {n_cells_filled / (n_nodes * n_edges)}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6980b-72d6-4121-b1bd-3149fb6e894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[nodes] = df_filtered[nodes].map(lambda x:\"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "df_filtered[nodes].to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39d98d-0aa5-46d5-8695-21233c9cb476",
   "metadata": {},
   "source": [
    "### dblp-v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd718be9-2a5c-42fe-a236-1c84b6a38292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dblp-v\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"author\"\n",
    "files = get_files(path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f768f-cb6f-4bbf-9f71-84a3dfb7fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df = df[[nodes]]\n",
    "    df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x:x.split(\";\"))\n",
    "    df_filtered = df_filtered[~(df_filtered[nodes].map(len) < 1)].copy()\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6332e1-2b2a-4fea-a53c-e6e6529afd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b74b29-45fc-4b1c-bbaa-616ba093a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \n",
    "                                         header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093daf04-a5f8-4ecd-9f05-6942a02bc55f",
   "metadata": {},
   "source": [
    "### mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d83e9-2ca0-47b8-83cb-37c76f222ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mus\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"frequencies440\"\n",
    "files = sorted(glob(f\"{path}/{dataset}/**.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184586e6-e0f1-445b-bd6b-1aa52f03c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df = df[[nodes]]\n",
    "    df_filtered = df[~(df[nodes].map(len) < 3)].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647671f-afd1-4e03-8fdf-af3bdd9da5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac438b-72d3-4d74-8807-320802ac22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12888c24-8aa8-4c59-b3e6-1fd1748f514e",
   "metadata": {},
   "source": [
    "### ndc-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998e5da-8a01-43a4-bc22-260722b998d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ndc-ai\"\n",
    "nodes = \"active_ingredients_names\"\n",
    "dataset_type = \"ihg\"\n",
    "files = get_files(path, dataset)\n",
    "file = files[0]\n",
    "with gzip.open(file) as f:\n",
    "    df = pd.read_csv(file)\n",
    "df = df[[nodes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab373592-c7a4-4b5d-8160-cd25289f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[~(df[nodes].map(len) < 3)].copy()\n",
    "df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "n_cells_filled = len(df_filtered[nodes].explode())\n",
    "n_edges = len(df_filtered)\n",
    "\n",
    "node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "n_nodes = len(node_mapping)\n",
    "\n",
    "print(\n",
    "    f\"n: {n_nodes}, m:{n_edges}\", \n",
    "    f\"c: {n_cells_filled}, c/nm: {n_cells_filled / (n_nodes * n_edges)}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd2689-6a5e-47bb-8453-6dfb169b8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[nodes] = df_filtered[nodes].map(lambda x:\"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "df_filtered[nodes].to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1dac69-0000-4216-9197-10ce1820bda7",
   "metadata": {},
   "source": [
    "### ndc-pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac3932-846e-4f18-a405-65002e68834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ndc-pc\"\n",
    "nodes = \"pharm_class\"\n",
    "dataset_type = \"ihg\"\n",
    "files = get_files(path, dataset)\n",
    "file = files[0]\n",
    "with gzip.open(file) as f:\n",
    "    df = pd.read_csv(file)\n",
    "df = df[[nodes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05a60d-50c6-4c2a-8d43-7e3618c14af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[~(df[nodes].fillna(\"\").map(len) < 3)].copy()\n",
    "df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "n_cells_filled = len(df_filtered[nodes].explode())\n",
    "n_edges = len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a31d0-4efc-4d5d-bd94-296183e8f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "n_nodes = len(node_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f0a8-7bdc-4182-841b-fbff03f32d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"n: {n_nodes}, m:{n_edges}\", \n",
    "    f\"c: {n_cells_filled}, c/nm: {n_cells_filled / (n_nodes * n_edges)}\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181266f-500e-4bc4-bd9d-3c8ef81713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[nodes] = df_filtered[nodes].map(lambda x:\"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "df_filtered[nodes].to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a478f84-a0ba-42e7-9137-f12c64a8ee6e",
   "metadata": {},
   "source": [
    "### sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c38ae-db8f-4d99-9f1c-ad6a17f2b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"sha\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"onstage\"\n",
    "files = sorted(glob(f\"{path}/{dataset}/**.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a5266-2517-40b8-8cdd-1541deb7c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df = df[[nodes]]\n",
    "    df_filtered = df[~(df[nodes].map(len) < 3)].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x:x.split())\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(\n",
    "            lambda x: [elem for elem in x if not elem.split(\"_\")[0].isupper()]\n",
    "        )\n",
    "    df_filtered = df_filtered[~(df_filtered[nodes].map(len) < 1)].copy()\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead10b0-ec98-4e30-b3df-52cb4ad80b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504302f-c657-42c6-921e-a8c2ded7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \n",
    "                                         header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314b02d-db0d-44e5-a381-cf8e6f06b805",
   "metadata": {},
   "source": [
    "### stex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbab1eb-a432-4533-aeba-52f16a446dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"stex\"\n",
    "dataset_type = \"chg\"\n",
    "nodes = \"tags\"\n",
    "files = get_files(path, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a1c5e-0dbf-4ff1-a1cb-46950bc02f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "stats = list()\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        df = pd.read_csv(file)\n",
    "    df_filtered = df[[nodes]].copy()\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(eval)\n",
    "    n_cells_filled = len(df_filtered[nodes].explode())\n",
    "    n_edges = len(df_filtered)\n",
    "    node_mapping = {x:idx for idx, x in enumerate(sorted(df_filtered[nodes].explode().unique()), start=1)}\n",
    "    n_nodes = len(node_mapping)\n",
    "    df_filtered[nodes] = df_filtered[nodes].map(lambda x: f\"{idx}\\t\" + \"\\t\".join([str(node_mapping[y]) for y in x]))\n",
    "    dfs.append(df_filtered.copy())\n",
    "    stats.append((n_nodes, n_edges, n_cells_filled, n_cells_filled/(n_nodes * n_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8339ec0-5209-41c4-b8bf-70a9bfa436a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(n/m)_max: {[tup[0]/tup[1] for tup in [max(stats, key=lambda tup:tup[0]/tup[1])]][0]}\")\n",
    "print(f\"(c/nm)_max: {[tup[-1] for tup in [max(stats, key=lambda tup:tup[-1])]][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1fa9c-241f-41a7-b351-3475113a7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs, ignore_index=True\n",
    "         ).to_csv(f\"../data/{dataset}.{dataset_type}.tsv.gz\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1abab2b-8a11-4472-b56e-6a0bdfc4746b",
   "metadata": {},
   "source": [
    "### syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cfd97-acf4-4502-9e7d-80e7d57d97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca065f7-9cd9-4cad-8a46-1bb9662dc74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"chg\"\n",
    "syn_datasets = [\"syn_hcm\", \"syn_hnmp\", \"syn_hsbm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca38461-d539-44d1-a7b7-8fe79437e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in syn_datasets:\n",
    "    files = get_files(path, dataset)\n",
    "    graph_strings = []\n",
    "    for idx,file in enumerate(files, start=1):\n",
    "        with gzip.open(file) as f:\n",
    "            data = json.load(f)\n",
    "        graph_strings.append(\"\\n\".join([f\"{idx}\\t\" + \"\\t\".join([str(x) for x in y]) for y in data[\"cr\"]]))\n",
    "    joined = \"\\n\".join(graph_strings)\n",
    "    \n",
    "    with gzip.open(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \"wt\") as f:\n",
    "        f.write(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea908d47-bebc-4874-835a-81c13eb7685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"chg\"\n",
    "\n",
    "dataset = \"syn_hcm\"\n",
    "files = get_files(path, \"syn_hcm\") + get_files(path, \"syn_hsbm\")\n",
    "graph_strings = []\n",
    "for idx,file in enumerate(files, start=1):\n",
    "    with gzip.open(file) as f:\n",
    "        data = json.load(f)\n",
    "    graph_strings.append(\"\\n\".join([f\"{idx}\\t\" + \"\\t\".join([str(x) for x in y]) for y in data[\"cr\"]]))\n",
    "joined = \"\\n\".join(graph_strings)\n",
    "dataset = \"syn_hcm-hsbm\"\n",
    "with gzip.open(f\"../data/{dataset}.{dataset_type}.tsv.gz\", \"wt\") as f:\n",
    "    f.write(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e031e06-31ed-42e6-b423-0b40c0c58f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
